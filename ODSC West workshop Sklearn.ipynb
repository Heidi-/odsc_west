{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bbc-text.csv\")\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list = stopword_list + [\"said\", \"also\", \"would\", \"first\", \"last\", \"one\"]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business', 'politics', 'tech', 'entertainment', 'sport'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df['category'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most frequent words\n",
    "def get_stats(words, num_words=200):\n",
    "    #words = [word for word in words if word not in stopword_list]\n",
    "    #words = [word for word in words if re.search(\"[A-Za-z]\", word)]\n",
    "    freq_dist = FreqDist(words)\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    print(df['text'])\n",
    "    df['word_list'] = df['text'].apply(lambda x: nltk.tokenize.word_tokenize(x))\n",
    "    df['word_list'] = df['word_list'].apply(lambda x: [word for word in x if word not in stopword_list])\n",
    "    df['word_list'] = df['word_list'].apply(lambda x: [word for word in x if re.search(\"[A-Za-z]\", word)])\n",
    "    df['lemmas'] = df['word_list'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       tv future in the hands of viewers with home th...\n",
      "1       worldcom boss  left books alone  former worldc...\n",
      "2       tigers wary of farrell  gamble  leicester say ...\n",
      "3       yeading face newcastle in fa cup premiership s...\n",
      "4       ocean s twelve raids box office ocean s twelve...\n",
      "                              ...                        \n",
      "2220    cars pull down us retail figures us retail sal...\n",
      "2221    kilroy unveils immigration policy ex-chatshow ...\n",
      "2222    rem announce new glasgow concert us band rem h...\n",
      "2223    how political squabbles snowball it s become c...\n",
      "2224    souness delight at euro progress boss graeme s...\n",
      "Name: text, Length: 2225, dtype: object\n",
      "           category                                               text  \\\n",
      "0              tech  tv future in the hands of viewers with home th...   \n",
      "1          business  worldcom boss  left books alone  former worldc...   \n",
      "2             sport  tigers wary of farrell  gamble  leicester say ...   \n",
      "3             sport  yeading face newcastle in fa cup premiership s...   \n",
      "4     entertainment  ocean s twelve raids box office ocean s twelve...   \n",
      "...             ...                                                ...   \n",
      "2220       business  cars pull down us retail figures us retail sal...   \n",
      "2221       politics  kilroy unveils immigration policy ex-chatshow ...   \n",
      "2222  entertainment  rem announce new glasgow concert us band rem h...   \n",
      "2223       politics  how political squabbles snowball it s become c...   \n",
      "2224          sport  souness delight at euro progress boss graeme s...   \n",
      "\n",
      "                                              word_list  \\\n",
      "0     [tv, future, hands, viewers, home, theatre, sy...   \n",
      "1     [worldcom, boss, left, books, alone, former, w...   \n",
      "2     [tigers, wary, farrell, gamble, leicester, say...   \n",
      "3     [yeading, face, newcastle, fa, cup, premiershi...   \n",
      "4     [ocean, twelve, raids, box, office, ocean, twe...   \n",
      "...                                                 ...   \n",
      "2220  [cars, pull, us, retail, figures, us, retail, ...   \n",
      "2221  [kilroy, unveils, immigration, policy, ex-chat...   \n",
      "2222  [rem, announce, new, glasgow, concert, us, ban...   \n",
      "2223  [political, squabbles, snowball, become, commo...   \n",
      "2224  [souness, delight, euro, progress, boss, graem...   \n",
      "\n",
      "                                                 lemmas  \n",
      "0     [tv, future, hand, viewer, home, theatre, syst...  \n",
      "1     [worldcom, bos, left, book, alone, former, wor...  \n",
      "2     [tiger, wary, farrell, gamble, leicester, say,...  \n",
      "3     [yeading, face, newcastle, fa, cup, premiershi...  \n",
      "4     [ocean, twelve, raid, box, office, ocean, twel...  \n",
      "...                                                 ...  \n",
      "2220  [car, pull, u, retail, figure, u, retail, sale...  \n",
      "2221  [kilroy, unveils, immigration, policy, ex-chat...  \n",
      "2222  [rem, announce, new, glasgow, concert, u, band...  \n",
      "2223  [political, squabble, snowball, become, common...  \n",
      "2224  [souness, delight, euro, progress, bos, graeme...  \n",
      "\n",
      "[2225 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 7254), ('mr', 2994), ('would', 2577), ('also', 2156), ('people', 2044), ('new', 1970), ('us', 1932), ('year', 1829), ('one', 1763), ('could', 1511), ('last', 1381), ('first', 1282), ('world', 1186), ('two', 1181), ('government', 1154), ('time', 1147), ('uk', 1079), ('years', 1002), ('make', 927), ('best', 926), ('told', 911), ('get', 890), ('game', 857), ('made', 856), ('film', 855), ('like', 838), ('music', 835), ('many', 829), ('labour', 796), ('next', 780), ('bbc', 765), ('back', 764), ('three', 762), ('number', 760), ('take', 735), ('added', 731), ('way', 726), ('set', 714), ('well', 701), ('says', 687), ('market', 686), ('company', 685), ('may', 685), ('home', 648), ('good', 642), ('going', 624), ('still', 622), ('england', 616), ('games', 615), ('election', 613), ('party', 610), ('much', 609), ('win', 607), ('since', 607), ('firm', 606), ('work', 603), ('go', 598), ('blair', 598), ('show', 593), ('think', 586), ('use', 582), ('say', 581), ('week', 575), ('million', 570), ('play', 565), ('part', 565), ('minister', 557), ('want', 556), ('public', 555), ('technology', 553), ('top', 553), ('second', 546), ('see', 544), ('british', 533), ('used', 526), ('players', 522), ('news', 518), ('european', 517), ('mobile', 515), ('country', 515), ('however', 514), ('tv', 504), ('group', 498), ('even', 494), ('expected', 493), ('sales', 493), ('end', 487), ('plans', 486), ('five', 482), ('already', 472), ('put', 471), ('brown', 468), ('come', 466), ('growth', 466), ('months', 463), ('six', 456), ('service', 453), ('chief', 451), ('britain', 450), ('four', 450), ('economy', 449), ('former', 445), ('london', 445), ('net', 434), ('money', 432), ('director', 429), ('deal', 429), ('companies', 428), ('services', 427), ('according', 422), ('industry', 422), ('help', 421), ('need', 419), ('system', 418), ('digital', 415), ('users', 415), ('record', 410), ('right', 408), ('including', 407), ('europe', 405), ('tax', 404), ('international', 404), ('big', 403), ('place', 402), ('around', 401), ('day', 400), ('firms', 396), ('report', 392), ('economic', 391), ('wales', 389), ('business', 385), ('great', 385), ('really', 384), ('move', 383), ('software', 382), ('another', 381), ('bank', 380), ('got', 377), ('future', 373), ('phone', 371), ('month', 368), ('third', 366), ('took', 366), ('club', 364), ('howard', 364), ('team', 363), ('open', 363), ('general', 360), ('came', 360), ('start', 359), ('france', 359), ('know', 358), ('spokesman', 356), ('information', 354), ('hit', 353), ('better', 352), ('radio', 347), ('video', 345), ('online', 344), ('without', 343), ('office', 342), ('final', 342), ('united', 335), ('life', 335), ('high', 335), ('court', 335), ('law', 334), ('despite', 334), ('ireland', 334), ('decision', 333), ('found', 331), ('campaign', 331), ('far', 328), ('likely', 328), ('using', 326), ('action', 325), ('side', 324), ('prime', 324), ('seen', 324), ('data', 324), ('figures', 323), ('real', 322), ('security', 322), ('give', 321), ('saying', 321), ('media', 319), ('china', 319), ('lot', 317), ('given', 317), ('computer', 317), ('president', 316), ('national', 316), ('awards', 316), ('offer', 313), ('away', 312), ('called', 311), ('able', 311), ('countries', 311), ('every', 310), ('executive', 308)]\n"
     ]
    }
   ],
   "source": [
    "flattened = [word for article in df['word_list'].values for word in article]\n",
    "fd = get_stats(flattened)\n",
    "#print(fd.most_common(num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-grams\n",
    "def get_ngrams(df, input_col_name, output_col_name, ngram_func):\n",
    "    df[output_col_name] = df[input_col_name].apply(lambda x: list(ngram_func(x)))\n",
    "    df[output_col_name] = df[output_col_name].apply(lambda x: [bigram for bigram in x \n",
    "                                                   if bigram[0] not in stopword_list\n",
    "                                                  and bigram[1] not in stopword_list])\n",
    "    df[output_col_name] = df[output_col_name].apply(lambda x: [bigram for bigram in x \n",
    "                                                   if re.search(\"[A-Za-z]\", bigram[0])\n",
    "                                                  and re.search(\"[A-Za-z]\", bigram[1])])\n",
    "    df[output_col_name] = df[output_col_name].apply(lambda x: [\" \".join(bigram) for bigram in x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('last year', 454), ('told bbc', 362), ('said mr', 359), ('mr blair', 332), ('prime minister', 312), ('mr brown', 255), ('chief executive', 198), ('said would', 192), ('tony blair', 186), ('last week', 184), ('bbc news', 178), ('general election', 172), ('new york', 167), ('six nations', 162), ('mr howard', 155), ('number one', 141), ('first time', 140), ('michael howard', 130), ('years ago', 128), ('human rights', 118), ('next year', 116), ('gordon brown', 113), ('bbc radio', 112), ('also said', 105), ('mobile phone', 104), ('home secretary', 104), ('two years', 102), ('lib dems', 102), ('new zealand', 99), ('news website', 98), ('five years', 93), ('three years', 93), ('liberal democrats', 93), ('three months', 91), ('spokesman said', 91), ('last month', 90), ('box office', 89), ('manchester united', 87), ('world cup', 87), ('interest rates', 80), ('economic growth', 80), ('mobile phones', 79), ('grand slam', 79), ('lib dem', 78), ('blair said', 76), ('tory leader', 75), ('labour party', 74), ('stock market', 74), ('champions league', 71), ('bbc sport', 70), ('around world', 69), ('australian open', 67), ('analysts said', 66), ('mr kennedy', 66), ('next week', 65), ('mr blunkett', 65), ('deutsche boerse', 65), ('said statement', 64), ('liberal democrat', 64), ('election campaign', 64), ('make sure', 63), ('council tax', 63), ('south africa', 62), ('four years', 62), ('oil prices', 62), ('many people', 62), ('los angeles', 61), ('howard said', 61), ('united states', 59), ('legal action', 59), ('id cards', 58), ('leader michael', 58), ('digital music', 58), ('today programme', 57), ('next generation', 57), ('mr kilroy-silk', 57), ('next month', 56), ('european union', 56), ('home office', 56), ('new year', 56), ('stock exchange', 55), ('young people', 55), ('million people', 55), ('take place', 54), ('company said', 54), ('radio today', 53), ('million dollar', 53), ('dollar baby', 53), ('downing street', 52), ('first half', 52), ('davis cup', 52), ('best film', 52), ('foreign secretary', 52), ('mr clarke', 51), ('would like', 51), ('mac mini', 51), ('world number', 50), ('six months', 50), ('second half', 50), ('named best', 50), ('mr ebbers', 49), ('charles kennedy', 49), ('minimum wage', 49), ('south korea', 48), ('would also', 48), ('public services', 48), ('mr straw', 48), ('consumer electronics', 47), ('next election', 47), ('bbc one', 47), ('said new', 47), ('last years', 47), ('house lords', 46), ('would make', 46), ('vera drake', 46), ('mr glazer', 46), ('earlier month', 45), ('news agency', 45), ('take part', 45), ('iraq war', 45), ('new labour', 45), ('recent years', 44), ('sri lanka', 44), ('even though', 44), ('later year', 44), ('vice president', 43), ('best director', 43), ('earlier year', 43), ('best actress', 43), ('consumer spending', 43), ('film festival', 42), ('video games', 42), ('told reuters', 41), ('income tax', 41), ('said government', 41), ('fourth quarter', 40), ('music industry', 40), ('people would', 40), ('would take', 39), ('could also', 39), ('attorney general', 39), ('northern ireland', 39), ('bank england', 39), ('said think', 39), ('next general', 39), ('president bush', 39), ('real madrid', 39), ('said people', 39), ('england wales', 39), ('music players', 39), ('ask jeeves', 39), ('earlier week', 38), ('house prices', 38), ('housing market', 38), ('said one', 38), ('said many', 37), ('tax cuts', 37), ('best actor', 36), ('would mean', 36), ('five million', 36), ('local government', 36), ('jamie foxx', 36), ('said ms', 35), ('without trial', 35), ('political parties', 35), ('people want', 35), ('hard drive', 35), ('brown said', 35), ('says mr', 34), ('martin scorsese', 34), ('house arrest', 34), ('would allow', 34), ('government said', 34), ('us court', 34), ('would put', 34), ('lord goldsmith', 34), ('lord chancellor', 34), ('us economy', 34), ('operating system', 34), ('best supporting', 34), ('search engine', 33), ('two weeks', 33), ('world biggest', 33), ('harry potter', 33), ('chancellor gordon', 33), ('r b', 33), ('hong kong', 33), ('camera phones', 33), ('interest rate', 33), ('cross country', 33), ('joss stone', 33), ('let people', 33), ('mr milburn', 32), ('could help', 32), ('said wanted', 32), ('managing director', 32), ('law lords', 32), ('would continue', 32), ('leader charles', 32), ('minister said', 32)]\n"
     ]
    }
   ],
   "source": [
    "df = get_ngrams(df, \"word_list\", \"bigrams\", nltk.bigrams)\n",
    "flattened_bigrams = [ngram for article in df['bigrams'].values for ngram in article]\n",
    "fd = get_stats(flattened_bigrams)\n",
    "#print(fd.most_common(num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('told bbc news', 147), ('bbc news website', 97), ('told bbc radio', 76), ('leader michael howard', 58), ('mr blair said', 54), ('million dollar baby', 53), ('radio today programme', 49), ('told bbc sport', 48), ('bbc radio today', 47), ('mr howard said', 41), ('tory leader michael', 41), ('next general election', 39), ('chancellor gordon brown', 33), ('leader charles kennedy', 32), ('prime minister tony', 32), ('minister tony blair', 32), ('two years ago', 28), ('george w bush', 28), ('world number one', 27), ('mr blair told', 27), ('coach andy robinson', 27), ('bbc world service', 26), ('london stock exchange', 25), ('said mr blair', 25), ('deputy prime minister', 23), ('sir alex ferguson', 23), ('digital music players', 23), ('radio five live', 23), ('foreign secretary jack', 22), ('secretary jack straw', 22), ('secretary charles clarke', 22), ('consumer electronics show', 21), ('uk independence party', 21), ('rbs six nations', 21), ('securities exchange commission', 21), ('mr brown said', 21), ('home secretary charles', 21), ('us box office', 20), ('tony blair said', 20), ('european indoor championships', 20), ('mr straw said', 20), ('actor jamie foxx', 20), ('reuters news agency', 20), ('prime minister said', 20), ('bbc radio five', 20), ('first time since', 19), ('home secretary david', 19), ('liberal democrat leader', 19), ('spokesman mark oaten', 18), ('president george w', 18), ('mr blair mr', 18), ('michael howard said', 17), ('shadow home secretary', 17), ('sir clive woodward', 17), ('shadow chancellor oliver', 17), ('chancellor oliver letwin', 17), ('best supporting actor', 17), ('said prime minister', 17), ('mr kennedy said', 17), ('international monetary fund', 17), ('mr brown would', 17), ('mr clarke said', 16), ('democrat leader charles', 16), ('last three months', 16), ('gross domestic product', 16), ('blair mr brown', 16), ('first grand slam', 16), ('five years ago', 16), ('convention human rights', 16), ('world cross country', 16), ('tour new zealand', 16), ('today programme mr', 15), ('berlin film festival', 15), ('european convention human', 15), ('office national statistics', 15), ('home affairs spokesman', 15), ('england coach andy', 14), ('french open champion', 14), ('best supporting actress', 14), ('chief operating officer', 14), ('eternal sunshine spotless', 14), ('sunshine spotless mind', 14), ('co-chairman liam fox', 14), ('lib dem leader', 14), ('three years ago', 14), ('affairs spokesman mark', 14), ('end last year', 14), ('jamie foxx actress', 14), ('best song last', 14), ('show las vegas', 13), ('chief financial officer', 13), ('prime minister mr', 13), ('secretary david davis', 13), ('prime minister john', 13), ('international rugby board', 13), ('told reuters news', 13), ('national audit office', 13), ('coach mike ruddock', 13), ('current account deficit', 13), ('local income tax', 13), ('said mr brown', 13), ('director martin scorsese', 13), ('song last years', 13), ('four years ago', 12), ('said last week', 12), ('bbc news online', 12), ('world trade organisation', 12), ('mr brown also', 12), ('uk film council', 12), ('said chief executive', 12), ('next three years', 12), ('kenteris katerina thanou', 12), ('lib dems say', 12), ('interest rate rises', 12), ('high oil prices', 12), ('minister john prescott', 12), ('programme go digital', 12), ('coach bernard laporte', 12), ('robert de niro', 12), ('da vinci code', 12), ('said mr irish', 12), ('digital video recorders', 11), ('electronics show las', 11), ('senior vice president', 11), ('law lords ruled', 11), ('conservative leader michael', 11), ('chairman matthew taylor', 11), ('election widely expected', 11), ('past five years', 11), ('founder mikhail khodorkovsky', 11), ('fraud tax evasion', 11), ('uk singles chart', 11), ('weapons mass destruction', 11), ('celebrity big brother', 11), ('home office minister', 11), ('digital rights management', 11), ('kostas kenteris katerina', 11), ('court arbitration sport', 11), ('bbc one breakfast', 11), ('one breakfast frost', 11), ('dem leader charles', 11), ('cross country championships', 11), ('gordon brown said', 11), ('carling cup final', 11), ('boss jose mourinho', 11), ('leader roger knapman', 11), ('number one uk', 11), ('general election mr', 11), ('sold million copies', 11), ('charles kennedy said', 11), ('actress hilary swank', 11), ('foreign terror suspects', 10), ('human rights laws', 10), ('spokesman told bbc', 10), ('general election widely', 10), ('told associated press', 10), ('rugby football union', 10), ('bankruptcy protection us', 10), ('three months september', 10), ('next five years', 10), ('three months december', 10), ('open source software', 10), ('harry potter prisoner', 10), ('potter prisoner azkaban', 10), ('mark oaten said', 10), ('black eyed peas', 10), ('liberal democrats say', 10), ('shadow foreign secretary', 10), ('foreign secretary michael', 10), ('secretary michael ancram', 10), ('world service programme', 10), ('service programme go', 10), ('last year said', 10), ('liam fox said', 10), ('chairman chief executive', 10), ('tests tel aviv', 10), ('tel aviv chicago', 10), ('mr kennedy also', 10), ('according financial times', 10), ('us stock market', 10), ('january transfer window', 10), ('public sector unions', 10), ('pew internet american', 10), ('internet american life', 10), ('foxx actress hilary', 10), ('new york times', 9), ('mr howard told', 9), ('former world number', 9), ('said would also', 9), ('slowdown housing market', 9), ('liberal democrats said', 9), ('general election campaign', 9), ('political ambitions founder', 9), ('ambitions founder mikhail', 9), ('president vladimir putin', 9), ('lord goldsmith said', 9), ('number one spot', 9), ('wales coach mike', 9), ('chancellor gerhard schroeder', 9), ('coach christos tzekos', 9)]\n"
     ]
    }
   ],
   "source": [
    "df = get_ngrams(df, \"word_list\", \"trigrams\", nltk.trigrams)\n",
    "flattened_trigrams = [ngram for article in df['trigrams'].values for ngram in article]\n",
    "fd = get_stats(flattened_trigrams)\n",
    "#print(fd.most_common(num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 7254), ('mr', 3035), ('year', 2831), ('would', 2577), ('also', 2156), ('people', 2045), ('new', 1970), ('u', 1935), ('one', 1809), ('could', 1511), ('game', 1472), ('time', 1449), ('last', 1381), ('first', 1283), ('say', 1268), ('world', 1214), ('government', 1190), ('two', 1181), ('company', 1113), ('film', 1113), ('uk', 1079), ('make', 1072), ('firm', 1002), ('get', 967), ('best', 930), ('told', 911), ('number', 893), ('service', 880), ('like', 879), ('take', 861), ('made', 856), ('way', 841), ('music', 835), ('month', 831), ('many', 829), ('country', 826), ('player', 820), ('market', 812), ('back', 805), ('labour', 796), ('week', 785), ('next', 780), ('party', 779), ('bbc', 765), ('set', 764), ('three', 762), ('show', 761), ('minister', 737), ('want', 736), ('sale', 734), ('home', 731), ('added', 731), ('well', 722), ('win', 706), ('election', 702), ('good', 700), ('plan', 695), ('go', 692), ('work', 691), ('may', 685), ('million', 681), ('day', 680), ('technology', 669), ('right', 663), ('come', 650), ('think', 640), ('second', 634), ('mobile', 633), ('play', 630), ('group', 629), ('still', 624), ('going', 624), ('part', 618), ('england', 616), ('much', 609), ('since', 607), ('see', 605), ('phone', 604), ('blair', 599), ('award', 595), ('use', 582), ('report', 576), ('need', 571), ('top', 563), ('public', 555), ('system', 552), ('european', 541), ('tax', 540), ('british', 533), ('used', 526), ('tv', 523), ('news', 518), ('however', 514), ('end', 511), ('tory', 510), ('share', 507), ('price', 501), ('put', 496), ('even', 494), ('record', 493), ('expected', 493), ('bank', 490), ('director', 489), ('business', 486), ('five', 482), ('deal', 481), ('economy', 479), ('place', 475), ('user', 475), ('already', 472), ('cost', 470), ('brown', 468), ('chief', 467), ('problem', 467), ('growth', 466), ('industry', 464), ('help', 462), ('law', 462), ('issue', 460), ('net', 459), ('six', 456), ('life', 453), ('britain', 452), ('four', 451), ('job', 447), ('former', 446), ('london', 445), ('hit', 438), ('star', 435), ('money', 432), ('thing', 430), ('figure', 429), ('computer', 426), ('rate', 426), ('team', 425), ('club', 424), ('according', 422), ('move', 419), ('know', 418), ('international', 417), ('decision', 416), ('change', 416), ('digital', 415), ('state', 415), ('network', 410), ('including', 407), ('europe', 405), ('offer', 404), ('look', 404), ('big', 403), ('analyst', 403), ('lord', 401), ('give', 401), ('around', 401), ('consumer', 400), ('open', 400), ('point', 400), ('cut', 399), ('side', 396), ('claim', 394), ('court', 394), ('start', 392), ('economic', 391), ('case', 390), ('great', 389), ('wale', 389), ('mean', 387), ('future', 384), ('really', 384), ('leader', 382), ('security', 382), ('software', 382), ('another', 381), ('got', 377), ('third', 376), ('executive', 376), ('office', 375), ('action', 372), ('took', 366), ('child', 365), ('howard', 364), ('rise', 364), ('site', 363), ('final', 362), ('lot', 361), ('france', 361), ('result', 361), ('video', 360), ('general', 360), ('came', 360), ('website', 358), ('match', 356), ('spokesman', 356), ('high', 355), ('information', 354), ('nation', 353), ('better', 352), ('radio', 349), ('campaign', 349), ('face', 348)]\n"
     ]
    }
   ],
   "source": [
    "#print(df['lemmas'])\n",
    "flattened_lemmas = [lemma for article in df['lemmas'].values for lemma in article]\n",
    "fd = get_stats(flattened_lemmas)\n",
    "#print(fd.most_common(num_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(sentence):\n",
    "    tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "    filtered_tokens = [t for t in tokens if t not in stopword_list and t not in string.punctuation and re.search('[a-zA-Z]', t)]\n",
    "    lemmas = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    filtered_tokens = [t for t in tokens if t not in stopword_list and t not in string.punctuation and re.search('[a-zA-Z]', t)]\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer(text_list):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.9, min_df=0.02, \n",
    "                                       ngram_range=(1,2), stop_words=stopword_list, tokenizer=tokenize_and_stem)\n",
    "    data = tfidf_vectorizer.fit_transform(text_list)\n",
    "    return (data, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenya\\Anaconda3\\envs\\nlp_book\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'s\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "(vect_data, vectorizer) = create_vectorizer(df['text'].values)\n",
    "#print(list(vectorizer.vocabulary_.keys())[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_fit_lda_sklearn(data, num_topics):\n",
    "    lda = LDA(n_components=num_topics)\n",
    "    lda.fit(data)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = create_and_fit_lda_sklearn(vect_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words_for_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    word_dict = {}\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        this_topic_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        word_dict[topic_index] = this_topic_words\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words(word_dict):\n",
    "    for key in word_dict.keys():\n",
    "        print(f\"Topic {key}\")\n",
    "        print(\"\\t\", word_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "\t ['said', 'compani', 'firm', 'use', 'mr', 'peopl', 'us', 'new', 'mobil', 'technolog']\n",
      "Topic 1\n",
      "\t ['growth', 'economi', 'rate', 'price', 'econom', 'bank', 'profit', 'rise', 'year', 'sale']\n",
      "Topic 2\n",
      "\t ['mr', 'labour', 'elect', 'parti', 'said', 'blair', 'tori', 'govern', 'minist', 'would']\n",
      "Topic 3\n",
      "\t ['film', 'game', 'play', 'said', 'win', 'best', 'award', 'star', 'year', 'england']\n",
      "Topic 4\n",
      "\t ['club', 'chelsea', 'arsenal', 'liverpool', 'unit', 'leagu', 'manchest', 'manchest unit', 'striker', 'footbal']\n"
     ]
    }
   ],
   "source": [
    "topic_words = get_most_common_words_for_topics(lda, vectorizer, 10)\n",
    "print_topic_words(topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with a new example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = \"\"\"Manchester United players slumped to the turf \n",
    "at full-time in Germany on Tuesday in acknowledgement of what their \n",
    "latest pedestrian first-half display had cost them. The 3-2 loss at \n",
    "RB Leipzig means United will not be one of the 16 teams in the draw \n",
    "for the knockout stages of the Champions League. And this is not the \n",
    "only price for failure. The damage will be felt in the accounts, in \n",
    "the dealings they have with current and potentially future players \n",
    "and in the faith the fans have placed in manager Ole Gunnar Solskjaer. \n",
    "With Paul Pogba's agent angling for a move for his client and ex-United \n",
    "defender Phil Neville speaking of a \"witchhunt\" against his former team-mate \n",
    "Solskjaer, BBC Sport looks at the ramifications and reaction to a big loss for United.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_example(lda, vect, example):\n",
    "    vectorized = vect.transform([example])\n",
    "    topic = lda.transform(vectorized)\n",
    "    print(topic)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74556144 0.16589133 0.02962948 0.02917745 0.0297403 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.74556144, 0.16589133, 0.02962948, 0.02917745, 0.0297403 ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_example(lda, vectorizer, new_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(lda, lda_path, vect, vect_path):\n",
    "    pickle.dump(lda, open(lda_path, 'wb'))\n",
    "    pickle.dump(vect, open(vect_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
